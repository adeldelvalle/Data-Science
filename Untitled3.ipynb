{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUWI8X/1R/SUvKuPOpo70A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeldelvalle/Data-Science/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YWL3fqWqkRC",
        "outputId": "d1b89846-a555-427c-f094-cdf71cb87ccb"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk \n",
        "import gensim\n",
        "import regex as re\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from nltk.tokenize import word_tokenize \n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "import re, string, unicodedata\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from gensim.models import FastText\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "data = pd.read_excel(\"rechazos.xlsx\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "vEmmAMuiqv3g",
        "outputId": "19959745-c15c-459a-c529-47de183dcc05"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>FechaEntrega</th>\n",
              "      <th>Region</th>\n",
              "      <th>EscuelaEstudiante</th>\n",
              "      <th>numeroDeEscuela</th>\n",
              "      <th>nombreEscuela</th>\n",
              "      <th>nombreEstudiante</th>\n",
              "      <th>numeroSIE</th>\n",
              "      <th>NombreTutor</th>\n",
              "      <th>TelefonoTutor</th>\n",
              "      <th>EmailTUtor</th>\n",
              "      <th>RazonRechazo</th>\n",
              "      <th>DetalleRechazo</th>\n",
              "      <th>CreatedBy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20210416-240943-9873</td>\n",
              "      <td>2021-04-16 15:33:39.6025137 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>CENTRO VOC. ESPECIAL</td>\n",
              "      <td>45310</td>\n",
              "      <td>CENTRO VOC. ESPECIAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Estudiante emigra a Estados Unidos</td>\n",
              "      <td>d45310@de.pr.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20210318-239435-4100</td>\n",
              "      <td>2021-03-18 13:18:02.4444357 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>DR. HERIBERTO DOMENECH</td>\n",
              "      <td>15792</td>\n",
              "      <td>DR. HERIBERTO DOMENECH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Fue entregada por desperfecto, necesita ser ar...</td>\n",
              "      <td>de124099@miescuela.pr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20210428-000818-9633</td>\n",
              "      <td>2021-04-28 13:41:47.8064027 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>EUGENIO MARÍA DE HOSTOS</td>\n",
              "      <td>48298</td>\n",
              "      <td>EUGENIO MARÍA DE HOSTOS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Examen ICPR</td>\n",
              "      <td>d48298@de.pr.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20210208-234177-2661</td>\n",
              "      <td>2021-02-08 15:55:54.9341474 +00:00</td>\n",
              "      <td>Humacao</td>\n",
              "      <td>ISABEL FLORES</td>\n",
              "      <td>34363</td>\n",
              "      <td>ISABEL FLORES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baja</td>\n",
              "      <td>d34363@de.pr.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20210414-240800-4538</td>\n",
              "      <td>2021-04-14 13:58:28.3496066 +00:00</td>\n",
              "      <td>Bayamón</td>\n",
              "      <td>DR. JOSÉ A. PADIN</td>\n",
              "      <td>70565</td>\n",
              "      <td>DR. JOSÉ A. PADIN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Estudiante esta descompensda emocionalmente y ...</td>\n",
              "      <td>d70565@de.pr.gov</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             identifier  ...              CreatedBy\n",
              "0  20210416-240943-9873  ...       d45310@de.pr.gov\n",
              "1  20210318-239435-4100  ...  de124099@miescuela.pr\n",
              "2  20210428-000818-9633  ...       d48298@de.pr.gov\n",
              "3  20210208-234177-2661  ...       d34363@de.pr.gov\n",
              "4  20210414-240800-4538  ...       d70565@de.pr.gov\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "jfXUOKTf9d6z",
        "outputId": "38861352-1dfa-4c35-8aef-4cc9a9857dc3"
      },
      "source": [
        "detalles = data[\"DetalleRechazo\"].astype(str).map(word_tokenize(language='spanish'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b7a4352cd0e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetalles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DetalleRechazo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spanish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: word_tokenize() missing 1 required positional argument: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSU_u27fuSBQ",
        "outputId": "e2b0a7b4-3bff-4ae0-b58f-b618bf36c1a0"
      },
      "source": [
        "data.DetalleRechazo.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Sdh9iiYF9jJT",
        "outputId": "418f9054-36e6-42ff-f4c9-4d6159ad2d61"
      },
      "source": [
        "detalles.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
            "Traceback (most recent call last):\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1709, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
            "TypeError: unhashable type: 'list'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan]                                                       456\n",
              "[Traslado de estudiante a otra escuela.]                     16\n",
              "[No aplica]                                                  15\n",
              "[No le interesa el equipo]                                   11\n",
              "[Baja]                                                       10\n",
              "                                                           ... \n",
              "[Estudiante no interesó equipo.]                              1\n",
              "[MADRE COMUNICA QUE ESTUDIANTE POSEE EQUIPO EN SU HOGAR]      1\n",
              "[Se traslado a EU]                                            1\n",
              "[No esta interesada en la tablet]                             1\n",
              "[El estudoiante se traslado a otra escuela]                   1\n",
              "Name: DetalleRechazo, Length: 276, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSAEgsrvqw_-"
      },
      "source": [
        "class Document:\n",
        "  \"\"\" Retrieve the narratives from the DataFrame and respectively\n",
        "  store and pre-process it. \n",
        "  \n",
        "  :param df: DataFrame including the reports and the predictor variable. \n",
        "  \n",
        "  \n",
        "  :ivar data: Stores the DataFrame.\n",
        "  :ivar text: Stores the narratives as string.\n",
        "  :ivar corpus: Stores the pre-processed text. \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, df):\n",
        "      self.data = df\n",
        "      self.text = df[\"DetalleRechazo\"].astype(str)\n",
        "      self.textPreProcessing()\n",
        "      \n",
        "      \n",
        "  def remove_non_ascii(self, words):\n",
        "      \"\"\"Remove non-ASCII characters from list of tokenized words\n",
        "      \n",
        "      :param words:  List of words to be transformed when removing non_ascii characters.\n",
        "      \n",
        "      :return new_words: List of words after the transformation of removed non_ascii characters. \"\"\"\n",
        "      new_words = []\n",
        "      for word in words:\n",
        "          new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "          new_words.append(new_word)\n",
        "      return new_words\n",
        "\n",
        "\n",
        "  def remove_punctuation(self, words):\n",
        "      \"\"\"Remove punctuation from list of tokenized words\n",
        "      \n",
        "      :param words:  List of words that will get remove their punctuations, if any. \n",
        "      \n",
        "      :return new_words: List of transformed words.\n",
        "      \n",
        "      \n",
        "      \"\"\"\n",
        "      new_words = []\n",
        "      for word in words:\n",
        "          new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "          if new_word != '':\n",
        "              new_words.append(new_word)\n",
        "      return new_words\n",
        "\n",
        "\n",
        "  def stem_words(self, words):\n",
        "      \"\"\"Stem words in list of tokenized words\n",
        "      \n",
        "      :param words:  List of words to be processed. \n",
        "      \n",
        "      :return new_words: List of the received words respective stems.\n",
        "      \n",
        "      \n",
        "      \"\"\"\n",
        "      \n",
        "      stemmer = LancasterStemmer()\n",
        "      stems = []\n",
        "      for word in words:\n",
        "          stem = stemmer.stem(word)\n",
        "          stems.append(stem)\n",
        "      return stems\n",
        "\n",
        "  def lemmatize_verbs(self, words):\n",
        "      \"\"\"Lemmatize verbs in list of tokenized words\n",
        "      \n",
        "      :param words:  List of words to be processed. \n",
        "      \n",
        "      :return new_words: List of the received words respective lemmas.\n",
        "      \n",
        "      \"\"\"\n",
        "      \n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      lemmas = []\n",
        "      for word in words:\n",
        "          lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "          lemmas.append(lemma)\n",
        "      return lemmas\n",
        "\n",
        "\n",
        "  def remove_stopwords(self, words):\n",
        "      \"\"\"Remove common words that have no meaning or importance in the sentence.\n",
        "      \n",
        "      :param words:  List of words to be processed and get stop words removed.. \n",
        "      \n",
        "      :return new_words: List of words with the stop words already removed. \"\"\"\n",
        "      \n",
        "      stop_words = set(stopwords.words('spanish')) \n",
        "      \n",
        "      for word in stop_words:\n",
        "          if word in words:\n",
        "              words.remove(word)\n",
        "              \n",
        "      return words\n",
        "\n",
        "  \n",
        "  \n",
        " \n",
        "  def clean_text_round1(self, text):\n",
        "      '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "      text = text.lower()\n",
        "      text = re.sub('\\[.*?¿\\]\\%', ' ', text)\n",
        "      text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "      text = re.sub('\\w*\\d\\w*', '', text)\n",
        "      return text\n",
        "\n",
        "\n",
        "  def normalize(self, words):\n",
        "      words = self.remove_non_ascii(words)\n",
        "      words = self.remove_punctuation(words)\n",
        "      words = self.lemmatize_verbs(words)\n",
        "      return words\n",
        "\n",
        "\n",
        "  def textPreProcessing(self):\n",
        "      \"\"\"Pre-process the text, normalize and clean it.\n",
        "      he function stores the cleaned text in the self.data\n",
        "      attribute. \"\"\"\n",
        "\n",
        "      clean_text = []\n",
        "\n",
        "      for narrative in self.text:\n",
        "          #tokenized_sentences = []\n",
        "          narrative = self.clean_text_round1(narrative)\n",
        "          narrative = word_tokenize(narrative, language='spanish')\n",
        "          sentence = self.normalize(narrative)\n",
        "          clean_text.append(sentence)\n",
        "          \n",
        "          \n",
        "                  \n",
        "      print(len(self.text), len(clean_text))\n",
        "      self.data[\"clean_text\"] = clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8yuCwINsC_q",
        "outputId": "be1a6cb3-4055-4eb4-dfae-0b62bd0b381a"
      },
      "source": [
        "rechazos = Document(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "830 830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "cdFZePUYsz4k",
        "outputId": "b5c92724-4804-426c-eb22-dd4a7c2b2f6f"
      },
      "source": [
        "rechazos.data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>FechaEntrega</th>\n",
              "      <th>Region</th>\n",
              "      <th>EscuelaEstudiante</th>\n",
              "      <th>numeroDeEscuela</th>\n",
              "      <th>nombreEscuela</th>\n",
              "      <th>nombreEstudiante</th>\n",
              "      <th>numeroSIE</th>\n",
              "      <th>NombreTutor</th>\n",
              "      <th>TelefonoTutor</th>\n",
              "      <th>EmailTUtor</th>\n",
              "      <th>RazonRechazo</th>\n",
              "      <th>DetalleRechazo</th>\n",
              "      <th>CreatedBy</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20210416-240943-9873</td>\n",
              "      <td>2021-04-16 15:33:39.6025137 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>CENTRO VOC. ESPECIAL</td>\n",
              "      <td>45310</td>\n",
              "      <td>CENTRO VOC. ESPECIAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Estudiante emigra a Estados Unidos</td>\n",
              "      <td>d45310@de.pr.gov</td>\n",
              "      <td>[estudiante, emigra, a, estados, unidos]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20210318-239435-4100</td>\n",
              "      <td>2021-03-18 13:18:02.4444357 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>DR. HERIBERTO DOMENECH</td>\n",
              "      <td>15792</td>\n",
              "      <td>DR. HERIBERTO DOMENECH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Fue entregada por desperfecto, necesita ser ar...</td>\n",
              "      <td>de124099@miescuela.pr</td>\n",
              "      <td>[fue, entregada, por, desperfecto, necesita, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20210428-000818-9633</td>\n",
              "      <td>2021-04-28 13:41:47.8064027 +00:00</td>\n",
              "      <td>Mayagüez</td>\n",
              "      <td>EUGENIO MARÍA DE HOSTOS</td>\n",
              "      <td>48298</td>\n",
              "      <td>EUGENIO MARÍA DE HOSTOS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Examen ICPR</td>\n",
              "      <td>d48298@de.pr.gov</td>\n",
              "      <td>[examen, icpr]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20210208-234177-2661</td>\n",
              "      <td>2021-02-08 15:55:54.9341474 +00:00</td>\n",
              "      <td>Humacao</td>\n",
              "      <td>ISABEL FLORES</td>\n",
              "      <td>34363</td>\n",
              "      <td>ISABEL FLORES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baja</td>\n",
              "      <td>d34363@de.pr.gov</td>\n",
              "      <td>[baja]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20210414-240800-4538</td>\n",
              "      <td>2021-04-14 13:58:28.3496066 +00:00</td>\n",
              "      <td>Bayamón</td>\n",
              "      <td>DR. JOSÉ A. PADIN</td>\n",
              "      <td>70565</td>\n",
              "      <td>DR. JOSÉ A. PADIN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Otra razón (Especifique debajo)</td>\n",
              "      <td>Estudiante esta descompensda emocionalmente y ...</td>\n",
              "      <td>d70565@de.pr.gov</td>\n",
              "      <td>[estudiante, esta, descompensda, emocionalment...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             identifier  ...                                         clean_text\n",
              "0  20210416-240943-9873  ...           [estudiante, emigra, a, estados, unidos]\n",
              "1  20210318-239435-4100  ...  [fue, entregada, por, desperfecto, necesita, s...\n",
              "2  20210428-000818-9633  ...                                     [examen, icpr]\n",
              "3  20210208-234177-2661  ...                                             [baja]\n",
              "4  20210414-240800-4538  ...  [estudiante, esta, descompensda, emocionalment...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzKk8SB1viST"
      },
      "source": [
        "corpus = rechazos.data.clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj8iCG_M2GNA",
        "outputId": "27bdac1a-a381-4517-ef80-25b966c221ab"
      },
      "source": [
        "corpus.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p12YTlU22KGY",
        "outputId": "b1ae336d-a40d-46a2-d0c4-d9a38086b6f5"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             [estudiante, emigra, a, estados, unidos]\n",
              "1    [fue, entregada, por, desperfecto, necesita, s...\n",
              "2                                       [examen, icpr]\n",
              "3                                               [baja]\n",
              "4    [estudiante, esta, descompensda, emocionalment...\n",
              "Name: clean_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv4emY-a8nKs",
        "outputId": "2178170a-7499-4771-d5b2-1521f660a0c1"
      },
      "source": [
        "corpus.astype(str).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nan']                                                                                                                         456\n",
              "['traslado', 'de', 'estudiante', 'a', 'otra', 'escuela']                                                                         18\n",
              "['no', 'aplica']                                                                                                                 15\n",
              "['no', 'le', 'interesa', 'el', 'equipo']                                                                                         11\n",
              "['baja']                                                                                                                         11\n",
              "                                                                                                                               ... \n",
              "['examen', 'icpr']                                                                                                                1\n",
              "['la', 'lat', 'top', 'esta', 'defectuosa']                                                                                        1\n",
              "['traslado', 'para', 'examenes', 'libres', 'grado']                                                                               1\n",
              "['no', 'le', 'permite', 'acceder', 'con', 'su', 'password', 'solo', 'en', 'su', 'equipo', 'personal']                             1\n",
              "['madre', 'indica', 'que', 'no', 'tiene', 'internet', 'en', 'su', 'hogar', 'utiliza', 'el', 'celular', 'para', 'conectarse']      1\n",
              "Name: clean_text, Length: 262, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMsPOzHBvmHR"
      },
      "source": [
        "model = FastText(corpus, min_count=2, workers=20, window=2, word_ngrams=1, alpha=0.02, hs=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkavNx1j2U7a"
      },
      "source": [
        "import gensim.corpora as corpora\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(corpus)\n",
        "# Create Corpus\n",
        "texts = corpus\n",
        "# Term Document Frequency\n",
        "corpus1 = [id2word.doc2bow(text) for text in texts]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh6IHn_S7b7C"
      },
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(corpus1)\n",
        "corpus_tfidf = tfidf[corpus1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPZRX2VZ5Opq",
        "outputId": "5ec6389e-1978-4a96-a47c-2ba177a103ba"
      },
      "source": [
        "from pprint import pprint\n",
        "# number of topics\n",
        "num_topics = 10\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus_tfidf,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=5,\n",
        "                                       passes=2,\n",
        "                                       workers=2)\n",
        "# Print the Keyword in the 10 topics\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.034*\"aplica\" + 0.031*\"No\" + 0.017*\"EQUIPO\" + 0.014*\"avisos\" + 0.014*\"equipo\" + 0.012*\"traslada\" + 0.012*\"ESTUDIANTE\" + 0.012*\"recoger\" + 0.012*\"Estudiante\" + 0.011*\"contesto\"\n",
            "Topic: 1 \n",
            "Words: 0.165*\"nan\" + 0.037*\"Baja\" + 0.032*\"interesa\" + 0.029*\"No\" + 0.024*\"equipo\" + 0.020*\"dio\" + 0.020*\"debaja\" + 0.016*\"Estudiante\" + 0.012*\"laptop\" + 0.011*\"escuela\"\n",
            "Topic: 2 \n",
            "Words: 0.033*\"traslado\" + 0.033*\"Equipo\" + 0.027*\"defectuoso\" + 0.021*\"Unidos\" + 0.020*\"EU\" + 0.020*\"Estados\" + 0.016*\"Se\" + 0.015*\"personal\" + 0.013*\"Traslado\" + 0.012*\"danado\"\n",
            "Topic: 3 \n",
            "Words: 0.022*\"equipo\" + 0.021*\"El\" + 0.018*\"Ya\" + 0.015*\"escuela\" + 0.009*\"computadora\" + 0.009*\"estudiante\" + 0.008*\"No\" + 0.008*\"interesada\" + 0.007*\"acepta\" + 0.007*\"Estudiante\"\n",
            "Topic: 4 \n",
            "Words: 0.564*\"nan\" + 0.025*\"escuela\" + 0.024*\"Traslado\" + 0.018*\"estudiante\" + 0.007*\"Estudiante\" + 0.005*\"traslado\" + 0.005*\"de\" + 0.005*\"La\" + 0.004*\"Se\" + 0.004*\"equipo\"\n"
          ]
        }
      ]
    }
  ]
}